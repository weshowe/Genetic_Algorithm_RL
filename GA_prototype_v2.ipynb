{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\monitoring\\video_recorder.py:9: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  import distutils.spawn\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dependencies: gym, ale-py\n",
    "\n",
    "pip install gym[atari,accept-rom-license]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "from functools import cmp_to_key\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_obs = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "\n",
    "])\n",
    "\n",
    "def obs_to_tensor(obs):\n",
    "   return torch.unsqueeze(torch.flatten(transform_obs(np.array(obs))), 0).to(device)\n",
    "\n",
    "\n",
    "# Initialize weights to something random.\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "# CNN used for determining actions.\n",
    "class Agent_CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() \n",
    "    self.model = nn.Sequential(\n",
    "            # Block 1\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), stride=(1,1), padding=(3,3), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Block 2\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Block 3\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Output\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(in_features=512, out_features=7, bias=True),\n",
    "                nn.Softmax(),\n",
    "            )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    arr = self.model(x)\n",
    "    arr = arr.cpu().detach().numpy()\n",
    "    action = np.argmax(arr)\n",
    "    return action\n",
    "  \n",
    "class Agent_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "      super().__init__() \n",
    "      self.model = nn.Sequential(\n",
    "        nn.Linear(100800, 1024),\n",
    "        nn.ReLU(),     \n",
    "        nn.Dropout(p=0.05),\n",
    "        nn.BatchNorm1d(1024),\n",
    "        nn.Linear(1024, 128),\n",
    "        nn.ReLU(),     \n",
    "        nn.Dropout(p=0.05),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.Linear(128, 7),\n",
    "        nn.ReLU(),     \n",
    "        nn.Dropout(p=0.05),\n",
    "        nn.BatchNorm1d(7),\n",
    "        nn.Softmax()\n",
    "      )\n",
    "\n",
    "      # Manually initialize random weights\n",
    "      self.model.apply(init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "      arr = self.model(x)\n",
    "      arr = arr.cpu().detach().numpy()\n",
    "      action = np.argmax(arr)\n",
    "      return action\n",
    "    \n",
    "    def getWeights(self):\n",
    "      weight_dict = {}\n",
    "      weight_dict[\"l1\"] = self.model[0].weight.cpu().detach().numpy()\n",
    "      weight_dict[\"l2\"] = self.model[4].weight.cpu().detach().numpy()\n",
    "      weight_dict[\"l3\"] = self.model[8].weight.cpu().detach().numpy()\n",
    "\n",
    "      return weight_dict\n",
    "    \n",
    "    def setWeights(self, weight_dict):\n",
    "\n",
    "      self.model[0].weight = nn.Parameter(torch.from_numpy(weight_dict[\"l1\"]).float().to(device))\n",
    "      self.model[4].weight = nn.Parameter(torch.from_numpy(weight_dict[\"l2\"]).float().to(device))\n",
    "      self.model[8].weight = nn.Parameter(torch.from_numpy(weight_dict[\"l3\"]).float().to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Action space is of size 7:\n",
    "\n",
    "0 NOOP\n",
    "1 FIRE\n",
    "2 UP\n",
    "3 RIGHT\n",
    "4 LEFT\n",
    "5 RIGHTFIRE\n",
    "6 LEFTFIRE\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "A class for each chromosome.\n",
    "\"\"\"\n",
    "class Chromosome:\n",
    "\n",
    "    \"\"\"\n",
    "    This is used to initialize a chromosome\n",
    "\n",
    "    args is used since Python doesn't support multiple constructors. (self, env) initializes a chromosome with a random\n",
    "    action sequence and is used during population initialization.\n",
    "\n",
    "    (self, actions, env) is used during crossover to generate new chromosomes given a crossed action buffer.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args):\n",
    "\n",
    "        if len(args) > 1:\n",
    "            self.nn = Agent_MLP()\n",
    "            self.nn.to(device)\n",
    "            self.nn.eval()\n",
    "            self.nn.setWeights(args[0])\n",
    "            self.env = args[1]\n",
    "            self.reward_sum = 0\n",
    "            self.time_alive = 0\n",
    "\n",
    "            return\n",
    "\n",
    "        # Stores actions taken, rewards obtained, total reward for the run, and the number of frames that the agent has been alive for.\n",
    "\n",
    "        self.nn = Agent_MLP()\n",
    "        self.nn.to(device)\n",
    "        self.nn.eval()\n",
    "        \n",
    "        self.action_buffer = []\n",
    "        self.reward_buffer = []\n",
    "\n",
    "        self.reward_sum = 0\n",
    "        self.time_alive = 0\n",
    "\n",
    "        # Store the provided env as a class variable.\n",
    "        self.env = args[0]\n",
    "\n",
    "        obs = self.env.reset()\n",
    "        done = False\n",
    "\n",
    "        num_lives = 4\n",
    "\n",
    "        while(done == False):\n",
    "\n",
    "            action = self.nn(obs_to_tensor(obs))\n",
    "\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "\n",
    "            self.action_buffer.append(action)\n",
    "            self.reward_buffer.append(reward)\n",
    "\n",
    "            self.time_alive = self.time_alive + 1\n",
    "            self.reward_sum = self.reward_sum + reward\n",
    "\n",
    "            if info['lives'] > num_lives:\n",
    "                num_lives = info['lives']\n",
    "\n",
    "            if info['lives'] < num_lives:\n",
    "                break\n",
    "\n",
    "    \"\"\"\n",
    "    This reruns the environment and performs a new run with the updated action buffer to generate new stats.\n",
    "    \"\"\"\n",
    "    def update(self):\n",
    "\n",
    "        # Stores updated actions and rewards taken.\n",
    "        self.nn.eval()\n",
    "        \n",
    "        new_action_buffer = []\n",
    "        new_reward_buffer = []\n",
    "\n",
    "        counter = 0\n",
    "\n",
    "        self.reward_sum = 0\n",
    "        self.time_alive = 0\n",
    "\n",
    "        obs = self.env.reset()\n",
    "\n",
    "        done = False\n",
    "\n",
    "        num_lives = 4\n",
    "\n",
    "        while(done == False):\n",
    "\n",
    "            # Determine if action is from supplied buffer or random.\n",
    "            counter = counter + 1\n",
    "\n",
    "            action = self.nn(obs_to_tensor(obs))\n",
    "\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "\n",
    "            new_action_buffer.append(action)\n",
    "            new_reward_buffer.append(reward)\n",
    "            self.time_alive = self.time_alive + 1\n",
    "            self.reward_sum = self.reward_sum + reward\n",
    "\n",
    "            if info['lives'] > num_lives:\n",
    "                num_lives = info['lives']\n",
    "\n",
    "            if info['lives'] < num_lives:\n",
    "                break\n",
    "\n",
    "        self.action_buffer = new_action_buffer\n",
    "        self.reward_buffer = new_reward_buffer\n",
    "\n",
    "    \"\"\"\n",
    "    Since the environment has a certain level of randomness, this function reruns it without saving results\n",
    "    except the aggregate reward and time alive. Used to gauge how accurate a score is during fitness.\n",
    "    \"\"\"\n",
    "    def simulate(self):\n",
    "\n",
    "        # This is needed in case we manage to survive for more frames than the action buffer has actions, in which case we do random ones.\n",
    "        counter = 0\n",
    "\n",
    "        new_reward_sum = 0\n",
    "        new_time_alive = 0\n",
    "\n",
    "        obs = self.env.reset()\n",
    "\n",
    "        done = False\n",
    "\n",
    "        num_lives = 4\n",
    "\n",
    "        while(done == False):\n",
    "\n",
    "            # Determine if action is from supplied buffer or random.\n",
    "            counter = counter + 1\n",
    "\n",
    "            action = self.nn(obs_to_tensor(obs))\n",
    "\n",
    "            obs, reward, done, info = self.env.step(action)\n",
    "\n",
    "            new_time_alive = self.time_alive + 1\n",
    "            new_reward_sum = self.reward_sum + reward\n",
    "\n",
    "            if info['lives'] > num_lives:\n",
    "                num_lives = info['lives']\n",
    "\n",
    "            if info['lives'] < num_lives:\n",
    "                break\n",
    "\n",
    "        return new_reward_sum, new_time_alive\n",
    "\n",
    "    \"\"\"\n",
    "    This mutates a chromosome's genes (NN weights) based on a supplied probability. If the mutation occurs, the action is replaced with a random one.\n",
    "    \"\"\"\n",
    "    def mutate(self, mutation_rate, mutation_factor=0.01):\n",
    "        weight_dict = self.nn.getWeights()\n",
    "        for key, val in weight_dict.items():\n",
    "            for i in range(0, len(val)):\n",
    "                for j in range(0, len(val[i])):\n",
    "                    if random.random() <= mutation_rate:\n",
    "                        curWeight = val[i][j]\n",
    "                        mutation_amount = curWeight * mutation_factor\n",
    "                        if random.random() >= 0.5:\n",
    "                            val[i][j] = curWeight + mutation_amount\n",
    "                        else:\n",
    "                            val[i][j] = curWeight - mutation_amount\n",
    "\n",
    "            weight_dict[key] = val\n",
    "\n",
    "        self.nn.setWeights(weight_dict)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "GA and helper methods\n",
    "\"\"\"\n",
    "\n",
    "#Comparator for a Chromosome list\n",
    "def chromosome_comparator(a, b):\n",
    "    if a.reward_sum > b.reward_sum:\n",
    "        return -1\n",
    "    elif a.reward_sum == b.reward_sum:\n",
    "        if a.time_alive < b.time_alive:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Feed this to sorting function\n",
    "compare_key = cmp_to_key(chromosome_comparator)\n",
    "\n",
    "# Generates initial population\n",
    "def create_initial_population(number, env):\n",
    "    population = []\n",
    "\n",
    "    for i in range(0, number):\n",
    "        print(i)\n",
    "        population.append(Chromosome(env))\n",
    "\n",
    "    return population\n",
    "\n",
    "\"\"\"\n",
    "Applies a fitness function and then ranks the population in descending order of best to worst.\n",
    "\n",
    "In this case, the primary marker of fitness is the high score. Assuming a tie, then secondary criterion is how long each agent has been alive.\n",
    "\n",
    "Also returns the best chromosome found.\n",
    "\"\"\"\n",
    "def selection(population):\n",
    "\n",
    "    # The first stage is the fitness function.\n",
    "    optimal_index = 0\n",
    "    longest_alive = 1000000\n",
    "    max_score = 0\n",
    "\n",
    "    for i, chrom in enumerate(population):\n",
    "\n",
    "        if chrom.reward_sum > max_score:\n",
    "            best = True\n",
    "        elif (chrom.reward_sum == max_score) and chrom.time_alive < longest_alive:\n",
    "            best = True\n",
    "        else:\n",
    "            best = False\n",
    "\n",
    "        if best:\n",
    "            longest_alive = chrom.time_alive\n",
    "            max_score = chrom.reward_sum\n",
    "            optimal_index = i\n",
    "\n",
    "    # Select best chromosome.\n",
    "    best_chromosome = population[optimal_index]\n",
    "\n",
    "    # Sort chromosomes in descending order.\n",
    "    population.sort(key=compare_key, reverse=True)\n",
    "\n",
    "    # This was for an AIS test, should remain commented out.\n",
    "\n",
    "    #for i in range(0, len(population)):\n",
    "        #population[i] = best_chromosome\n",
    "\n",
    "    # Select only the best 50% of chromosomes.\n",
    "    return population[0:int(len(population)/2)], best_chromosome\n",
    "\n",
    "\"\"\"\n",
    "Performs crossover on a population and returns the new population.\n",
    "\n",
    "Crossover is done by combining the weights of the parental nns.\n",
    "\"\"\"\n",
    "def crossover(population):\n",
    "    crossed_population = []\n",
    "    for i in range(0, len(population) - 1, 2):\n",
    "\n",
    "        father = population[i]\n",
    "\n",
    "        # Edge case if there's only 1 chromosome left, in which case it pairs with a random one.\n",
    "        if i + 1 > len(population) - 1:\n",
    "            mother = population[random.randint(0, len(population)-1)]\n",
    "            \n",
    "        else:\n",
    "            mother = population[i+1]\n",
    "\n",
    "        if father.reward_sum == 0 and mother.reward_sum == 0:\n",
    "            crossover_probability = 0.5\n",
    "        elif mother.reward_sum == 0 and father.reward_sum > 0:\n",
    "            crossover_probability = 0.999\n",
    "        elif father.reward_sum == 0 and mother.reward_sum > 0:\n",
    "            crossover_probability = 0.001\n",
    "\n",
    "        # Sample proportionally to the score\n",
    "        else:\n",
    "            crossover_probability = father.reward_sum / (father.reward_sum + mother.reward_sum)\n",
    "\n",
    "        if crossover_probability >= 0.999:\n",
    "            crossover_probability = 0.999\n",
    "\n",
    "        # They each have 4 kids, replenishing the population.\n",
    "        for j in range(0, 4):\n",
    "\n",
    "            motherWeights = mother.nn.getWeights()\n",
    "            fatherWeights = father.nn.getWeights()\n",
    "\n",
    "            newWeights = deepcopy(fatherWeights)\n",
    "\n",
    "            for key, val in newWeights.items():\n",
    "                for k in range(0, len(val)):\n",
    "                    for l in range(0, len(val[k])):\n",
    "                        if random.random() >= crossover_probability:\n",
    "                            val[k][l] = motherWeights[key][k][l]\n",
    "\n",
    "                newWeights[key] = val\n",
    "\n",
    "            crossed_population.append(Chromosome(newWeights, father.env))\n",
    "\n",
    "        #population[i] = None\n",
    "        #population[i+1] = None\n",
    "\n",
    "\n",
    "    return crossed_population\n",
    "\n",
    "\"\"\"\n",
    "Mutate the population. Rate represents chance of mutation.\n",
    "\"\"\"\n",
    "def mutate_population(population, rate=0.01):\n",
    "    for _, chrom in enumerate(population): \n",
    "        chrom.mutate(rate)\n",
    "\n",
    "\"\"\"\n",
    "Rerun the environment for all chromosomes and produce updated runs.\n",
    "\"\"\"\n",
    "def update_population(population):\n",
    "    for i, chrom in enumerate(population):     \n",
    "         chrom.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "Best Chromosome for Run 1 -> Longest Alive: 129    High Score: 84.0\n",
      "Best Chromosome for Run 2 -> Longest Alive: 199    High Score: 210.0\n",
      "Best Chromosome for Run 3 -> Longest Alive: 1505    High Score: 336.0\n",
      "Best Chromosome for Run 4 -> Longest Alive: 129    High Score: 0.0\n",
      "Best Chromosome for Run 5 -> Longest Alive: 65    High Score: 0.0\n",
      "Best Chromosome for Run 6 -> Longest Alive: 289    High Score: 0.0\n",
      "Best Chromosome for Run 7 -> Longest Alive: 1121    High Score: 0.0\n",
      "Best Chromosome for Run 8 -> Longest Alive: 1313    High Score: 0.0\n",
      "Best Chromosome for Run 9 -> Longest Alive: 609    High Score: 0.0\n",
      "Best Chromosome for Run 10 -> Longest Alive: 1825    High Score: 0.0\n",
      "Best Chromosome for Run 11 -> Longest Alive: 993    High Score: 0.0\n",
      "Best Chromosome for Run 12 -> Longest Alive: 289    High Score: 0.0\n",
      "Best Chromosome for Run 13 -> Longest Alive: 961    High Score: 0.0\n",
      "Best Chromosome for Run 14 -> Longest Alive: 161    High Score: 0.0\n",
      "Best Chromosome for Run 15 -> Longest Alive: 1345    High Score: 0.0\n",
      "Best Chromosome for Run 16 -> Longest Alive: 769    High Score: 0.0\n",
      "Best Chromosome for Run 17 -> Longest Alive: 545    High Score: 0.0\n",
      "Best Chromosome for Run 18 -> Longest Alive: 769    High Score: 0.0\n",
      "Best Chromosome for Run 19 -> Longest Alive: 1729    High Score: 0.0\n",
      "Best Chromosome for Run 20 -> Longest Alive: 929    High Score: 0.0\n",
      "Best Chromosome for Run 21 -> Longest Alive: 545    High Score: 0.0\n",
      "Best Chromosome for Run 22 -> Longest Alive: 833    High Score: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\icarus\\Documents\\school\\Winter 2023\\MAT 5182\\project\\Genetic_Algorithm_RL\\GA_prototype_v2.ipynb Cell 6\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest Chromosome for Run \u001b[39m\u001b[39m{\u001b[39;00mi \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m -> Longest Alive: \u001b[39m\u001b[39m{\u001b[39;00mlongest_alive\u001b[39m}\u001b[39;00m\u001b[39m    High Score: \u001b[39m\u001b[39m{\u001b[39;00mmax_score\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Cross, Mutate, Update, and prepare the new population for the next run.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m crossed_population \u001b[39m=\u001b[39m crossover(selected_population)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m mutate_population(crossed_population, mutation_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m update_population(crossed_population)\n",
      "\u001b[1;32mc:\\Users\\icarus\\Documents\\school\\Winter 2023\\MAT 5182\\project\\Genetic_Algorithm_RL\\GA_prototype_v2.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(val)):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m     \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(val[k])):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m         \u001b[39mif\u001b[39;00m random\u001b[39m.\u001b[39;49mrandom() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m crossover_probability:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m             val[k][l] \u001b[39m=\u001b[39m motherWeights[key][k][l]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W5sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m newWeights[key] \u001b[39m=\u001b[39m val\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GA loop\n",
    "\"\"\"\n",
    "\n",
    "env = gym.make('ALE/Assault-v5', full_action_space=False)\n",
    "\n",
    "n_iter = 200\n",
    "population_size = 4\n",
    "mutation_rate = 0.01\n",
    "\n",
    "best_alive = 0\n",
    "best_score = 0\n",
    "best_chromo = None\n",
    "\n",
    "population = create_initial_population(population_size, env)\n",
    "\n",
    "for i in range(0, n_iter):\n",
    "\n",
    "    # Run the fitness function and determine if the best chromosome is better than the best one we've stored for all runs.\n",
    "    selected_population, best_chromo_candidate = selection(population)\n",
    "    longest_alive = best_chromo_candidate.time_alive\n",
    "    max_score = best_chromo_candidate.reward_sum\n",
    "\n",
    "    if best_chromo_candidate.reward_sum > best_score:\n",
    "            best = True\n",
    "    elif (best_chromo_candidate.reward_sum == best_score) and best_chromo_candidate.time_alive < best_alive:\n",
    "            best = True\n",
    "    else:\n",
    "        if i == 0:\n",
    "                best = True\n",
    "        else:\n",
    "                best = False\n",
    "\n",
    "    if best:\n",
    "           best_chromo = deepcopy(best_chromo_candidate)\n",
    "           best_alive = best_chromo_candidate.time_alive\n",
    "           best_score = best_chromo_candidate.reward_sum\n",
    "           \n",
    "\n",
    "    # Print stats.\n",
    "    print(f\"Best Chromosome for Run {i + 1} -> Longest Alive: {longest_alive}    High Score: {max_score}\")\n",
    "\n",
    "    # Cross, Mutate, Update, and prepare the new population for the next run.\n",
    "    crossed_population = crossover(selected_population)\n",
    "    mutate_population(crossed_population, mutation_rate)\n",
    "    update_population(crossed_population)\n",
    "\n",
    "    population = crossed_population\n",
    "\n",
    "print(f\"Best Chromosome -> Longest Alive: {best_alive}    High Score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 210, 160])\n",
      "100800\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\icarus\\Documents\\school\\Winter 2023\\MAT 5182\\project\\Genetic_Algorithm_RL\\GA_prototype_v2.ipynb Cell 7\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W6sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     action \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m _, reward, done, info \u001b[39m=\u001b[39m test_env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W6sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m reward_sum \u001b[39m=\u001b[39m reward_sum \u001b[39m+\u001b[39m reward\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/icarus/Documents/school/Winter%202023/MAT%205182/project/Genetic_Algorithm_RL/GA_prototype_v2.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m time_alive \u001b[39m=\u001b[39m time_alive \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\time_limit.py:17\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m---> 17\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:13\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     12\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset, \u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling reset()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m     observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m observation, reward, done, info\n",
      "File \u001b[1;32mc:\\Users\\icarus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\envs\\atari\\environment.py:238\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[1;34m(self, action_ind)\u001b[0m\n\u001b[0;32m    236\u001b[0m reward \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m    237\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(frameskip):\n\u001b[1;32m--> 238\u001b[0m     reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39male\u001b[39m.\u001b[39mact(action)\n\u001b[0;32m    240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_obs(), reward, terminal, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_info()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This displays the game to evaluate our best chromosome.\n",
    "\"\"\"\n",
    "test_env = gym.make('ALE/Assault-v5', render_mode=\"human\", full_action_space=False)\n",
    "\n",
    "done = False\n",
    "obs = test_env.reset()\n",
    "\n",
    "transform_obs = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5]),\n",
    "\n",
    "])\n",
    "#convert_tensor = transforms.ToTensor()\n",
    "obs_ten = transform_obs(obs)\n",
    "print(obs_ten.shape)\n",
    "\n",
    "obs_np = np.array(obs)\n",
    "obs_flat = obs_np.flatten()\n",
    "\n",
    "print(len(obs_flat))\n",
    "\n",
    "time_alive = 0\n",
    "reward_sum = 0\n",
    "\n",
    "action_list = best_chromo.action_buffer\n",
    "limit = best_chromo.time_alive \n",
    "counter = 0\n",
    "\n",
    "while(done == False):\n",
    "\n",
    "    # Determine if action is from supplied buffer or random.\n",
    "    counter = counter + 1\n",
    "\n",
    "    if counter <= limit:\n",
    "        action = action_list[counter-1]\n",
    "    else:  \n",
    "        action = random.randint(0, 6)\n",
    "    \n",
    "    _, reward, done, info = test_env.step(action)\n",
    "\n",
    "    reward_sum = reward_sum + reward\n",
    "    time_alive = time_alive + 1\n",
    "\n",
    "print(f\"Longest Alive: {time_alive}    High Score: {reward_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "self.layers = nn.Sequential(\n",
    "      nn.Linear(21, 189),\n",
    "      nn.Hardswish(),     \n",
    "      nn.Dropout(p=0.05),\n",
    "      nn.BatchNorm1d(189),\n",
    "      nn.Linear(189, 63),\n",
    "      nn.Hardswish(),     \n",
    "      nn.Dropout(p=0.05),\n",
    "      nn.BatchNorm1d(63),\n",
    "      nn.Linear(63, 9),\n",
    "      nn.Hardswish(),     \n",
    "      nn.Dropout(p=0.05),\n",
    "      nn.BatchNorm1d(9),\n",
    "      nn.Linear(9, 1),\n",
    "      nn.Sigmoid()\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "# Function to instantiate the Torch MLP.\n",
    "class Agent(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() \n",
    "    self.model = nn.Sequential(\n",
    "            # Block 1\n",
    "                nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(7,7), stride=(1,1), padding=(3,3), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Block 2\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Block 3\n",
    "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3), stride=(2,2), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3), stride=(1,1), padding=(1,1), bias=False),\n",
    "                nn.BatchNorm2d(128),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                # Output\n",
    "                nn.Flatten(), \n",
    "                nn.Linear(in_features=512, out_features=7, bias=True),\n",
    "                nn.Softmax(),\n",
    "            )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "fuck = [0,1,2]\n",
    "print(fuck[0:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
